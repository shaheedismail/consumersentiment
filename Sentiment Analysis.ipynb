{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a58c22-58a7-43c2-9590-754f0601526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shaheedismail/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shaheedismail/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import contractions\n",
    "import re\n",
    "import string\n",
    "punctuation_string = string.punctuation\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "#nlp = spacy.load('en_core_web', disable=['parser', 'ner'])\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "sns.set(rc = {'figure.figsize':(8,5)})\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aebd835-9db0-4d54-b479-e8266e796163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load published index\n",
    "df_published = pd.read_csv('./data/GfK Consumer Confidence.csv', infer_datetime_format=True)\n",
    "df_published=df_published.set_index(['Date'])\n",
    "df_published.index =pd.to_datetime(df_published.index, infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7cffda-9e08-4c35-bf77-e25a5a412fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_in_directory(dir):\n",
    "    files = []\n",
    "    for file in os.listdir(dir):\n",
    "        f = os.path.join(dir, file)\n",
    "        product = file.split('.')[0]\n",
    "        if os.path.isfile(f):\n",
    "            files.append(f)\n",
    "    return files\n",
    "\n",
    "files = files_in_directory('./data/tweets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de969a84-9905-452f-b9ca-cbbff9983701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file './data/tweets/.DS_Store': 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "CPU times: user 10.6 s, sys: 1.92 s, total: 12.5 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dfs=[]\n",
    "all = False\n",
    "for file in files:\n",
    "\n",
    "    try:\n",
    "        if all:\n",
    "            if 'economy' in file and file != './data/tweets/.DS_Store':\n",
    "                df = pd.read_csv(file, low_memory=False,  lineterminator='\\n')\n",
    "                dfs.append(df)\n",
    "        else:\n",
    "            df = pd.read_csv(file, low_memory=False,  lineterminator='\\n')\n",
    "            dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file '{file}': {e}\")\n",
    "        continue\n",
    "\n",
    "df_all= pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "#df_all.to_csv('.data/economy_tweets.csv')\n",
    "#df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d33e52ec-5653-4239-acd2-56b9fb73645d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:16\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4889\u001b[0m, in \u001b[0;36mDataFrame.assign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   4886\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   4888\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 4889\u001b[0m     data[k] \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(v, data)\n\u001b[1;32m   4890\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/common.py:374\u001b[0m, in \u001b[0;36mapply_if_callable\u001b[0;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03mEvaluate possibly callable input using obj and kwargs if it is callable,\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03motherwise return as it is.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m**kwargs\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(maybe_callable):\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m maybe_callable(obj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_callable\n",
      "File \u001b[0;32m<timed exec>:36\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(df_)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:36\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:36\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mask = df_all['date'].str.match(r'\\d{4}-\\d{2}-\\d{2}')\n",
    "df = df_all[mask]\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "punctuation_string += '’'\n",
    "punctuation = str.maketrans('', '', punctuation_string)\n",
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "cleaned = (df\n",
    " #.sample(10)\n",
    " .loc[mask, :]\n",
    " .assign(date=pd.to_datetime(df_all.loc[mask, 'date'])\n",
    "        .dt.date)\n",
    " .query('lang==\"en\"')\n",
    " .drop(columns=df.columns[2:])\n",
    " .set_index('date')\n",
    " .assign(processed_text=lambda df_: df_.content\n",
    "         .astype(str)\n",
    "         .str.lower()\n",
    "         .apply(word_tokenize)\n",
    "         .apply(lambda tokens: ' '.join([w for w in tokens if not w in stop_words]))\n",
    "         .apply(lambda x: contractions.fix(x))\n",
    "         .apply(lambda x: re.sub('[0-9]+','', x)) #remove numbers\n",
    "         .apply(lambda x: re.sub('@ [A-z]+','',x)) #remove twitter handles\n",
    "         .apply(lambda x: x.translate(punctuation))\n",
    "         .apply(lambda x: re.sub(r'((http|ftp|https)://)?([\\w.-]*)\\.([\\w]*)+',' ', x)) #remove URLs\n",
    "         .apply(lambda x: re.sub(r'(http|ftp|https)://t\\.co/[a-zA-Z0-9\\-\\.]{10}', ' ', x)) #remove t.co URLs\n",
    "         .apply(lambda x: re.compile(pattern = \"[\" \n",
    "                                                u\"\\U0001F600-\\U0001F64F\"\n",
    "                                                u\"\\U0001F300-\\U0001F5FF\"\n",
    "                                                u\"\\U0001F680-\\U0001F6FF\"\n",
    "                                                u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                                                \"]+\", flags = re.UNICODE)\n",
    "                                                .sub(r'', x))\n",
    "         .apply(lambda x: re.sub(u\"\\uf8ff\", '', x))\n",
    "         .apply(lambda x: ' '.join(x.split()))\n",
    "         .apply(lambda x: ' '.join([token.lemma_ for token in nlp(x)]))\n",
    "         .apply(lambda x: re.sub('\\s\\S(?!\\S)|(?<!\\S)\\S\\s', '', x))\n",
    "         .apply(lambda x: re.sub(r'\\b\\w{16,}\\b', '', x))\n",
    "        )\n",
    " .dropna(subset='processed_text')\n",
    " .assign(tb_sentiment_score = lambda df_ : df_.processed_text.apply(lambda x: TextBlob(x).sentiment.polarity))\n",
    " .assign(tb_sentiment_cat = lambda df_: np.select([(df_.tb_sentiment_score.between(-0.05, 0.05)),\n",
    "                                                (df_.tb_sentiment_score>0),\n",
    "                                                (df_.tb_sentiment_score<0)],\n",
    "                                                 ['neut', 'pos', 'neg']))\n",
    " .astype({'tb_sentiment_cat': 'category'})\n",
    " .assign(tb_sentiment_score_round = lambda df_ : df_.tb_sentiment_cat.replace({'pos': 1, 'neut': 0, 'neg': -1}))\n",
    " .pipe(lambda df_: df_.set_index(pd.to_datetime(df_.index, format='%Y-%m-%d')))\n",
    "           \n",
    " .assign(vd_sentiment_score = lambda df_ : df_.processed_text.apply(lambda x: sid_obj.polarity_scores(str(x))['compound']))\n",
    " .assign(vd_sentiment_cat = lambda df_: np.select([(df_.vd_sentiment_score.between(-0.05, 0.05)),\n",
    "                                                (df_.vd_sentiment_score>0),\n",
    "                                                (df_.vd_sentiment_score<0)],\n",
    "                                                 ['neut', 'pos', 'neg']))\n",
    " .astype({'vd_sentiment_cat': 'category'})\n",
    " .assign(vd_sentiment_score_round = lambda df_ : df_.vd_sentiment_cat.replace({'pos': 1, 'neut': 0, 'neg': -1}))\n",
    " .pipe(lambda df_: df_.set_index(pd.to_datetime(df_.index, format='%Y-%m-%d')))      \n",
    " .assign(tokens = lambda df_: df_.processed_text\n",
    "         .astype(str)\n",
    "         .apply(word_tokenize))\n",
    ")\n",
    "\n",
    "\n",
    "cleaned.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a60d72f-f062-4094-95e2-f75f2610fb85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tb_result \u001b[38;5;241m=\u001b[39m (cleaned\n\u001b[1;32m      2\u001b[0m \u001b[38;5;241m.\u001b[39mgroupby([pd\u001b[38;5;241m.\u001b[39mGrouper(freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtb_sentiment_score_round\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;241m.\u001b[39magg(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m,numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;241m.\u001b[39massign(tb_sentiment_score\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m df_: \u001b[38;5;28mabs\u001b[39m(df_\u001b[38;5;241m.\u001b[39mtb_sentiment_score))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m3\u001b[39m:,[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;241m.\u001b[39munstack()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;241m.\u001b[39mdroplevel(\u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;241m.\u001b[39massign(tb_score \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;01mlambda\u001b[39;00m df_: (df_[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m df_[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39m(df_[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mdf_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mdf_[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m      9\u001b[0m [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtb_score\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;241m.\u001b[39mpipe(\u001b[38;5;28;01mlambda\u001b[39;00m df_: df_\u001b[38;5;241m.\u001b[39massign(date \u001b[38;5;241m=\u001b[39m df_\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;241m.\u001b[39massign(published \u001b[38;5;241m=\u001b[39m df_published[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;241m.\u001b[39mpipe(\u001b[38;5;28;01mlambda\u001b[39;00m df_: df_\u001b[38;5;241m.\u001b[39mset_index(pd\u001b[38;5;241m.\u001b[39mto_datetime(df_\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m fig, ax1 \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[1;32m     18\u001b[0m l1, \u001b[38;5;241m=\u001b[39m ax1\u001b[38;5;241m.\u001b[39mplot(tb_result\u001b[38;5;241m.\u001b[39mtb_score, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "tb_result = (cleaned\n",
    ".groupby([pd.Grouper(freq='M'),'tb_sentiment_score_round'])\n",
    ".agg('sum',numeric_only=True)\n",
    ".assign(tb_sentiment_score= lambda df_: abs(df_.tb_sentiment_score))\n",
    ".iloc[3:,[0]]\n",
    ".unstack()\n",
    ".droplevel(0, axis=1)\n",
    ".assign(tb_score =  lambda df_: (df_[1]- df_[-1])/(df_[1]+df_[0]+df_[-1]))\n",
    "[['tb_score']]\n",
    ".reset_index()\n",
    ".pipe(lambda df_: df_.assign(date = df_.date.dt.strftime('%Y-%m-%d')))\n",
    ".set_index('date')\n",
    ".assign(published = df_published[:-1])\n",
    ".pipe(lambda df_: df_.set_index(pd.to_datetime(df_.index, format='%Y-%m-%d')))\n",
    ")\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "l1, = ax1.plot(tb_result.tb_score, color='red', linewidth=2, label='model')\n",
    "ax2 = ax1.twinx()\n",
    "l2, = ax2.plot(tb_result.published, color='green', linewidth=2, label='published')\n",
    "plt.xticks(rotation=90)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Sentiment')\n",
    "ax2.set_ylabel('Published')\n",
    "plt.title('Twitter Sentiment TextBlob Model vs Published Consumer Confidence', fontsize=14)\n",
    "plt.legend(['model', 'published'], loc='lower center')\n",
    "plt.xlim([datetime.datetime(2015, 12, 31), datetime.datetime(2022, 12, 31)])\n",
    "for year in range(2010, 2023):\n",
    "    plt.axvline(pd.to_datetime(str(year) + '-01-01'), color='k', linestyle='--', alpha=0.2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd5729-6f3b-451e-908b-dd0fa824d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_result = (cleaned\n",
    ".groupby([pd.Grouper(freq='M'),'vd_sentiment_score_round'])\n",
    ".agg('sum',numeric_only=True)\n",
    ".assign(vd_sentiment_score= lambda df_: abs(df_.vd_sentiment_score))\n",
    ".iloc[3:,[1]]\n",
    ".unstack()\n",
    ".droplevel(0, axis=1)\n",
    ".assign(vd_score =  lambda df_: (df_[1]- df_[-1])/(df_[1]+df_[0]+df_[-1]))\n",
    "[['vd_score']]\n",
    ".reset_index()\n",
    ".pipe(lambda df_: df_.assign(date = df_.date.dt.strftime('%Y-%m-%d')))\n",
    ".set_index('date')\n",
    ".assign(published = df_published[:-1])\n",
    ".pipe(lambda df_: df_.set_index(pd.to_datetime(df_.index, format='%Y-%m-%d')))\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "l1, = ax1.plot(vd_result.vd_score, color='red', linewidth=2, label='model')\n",
    "ax2 = ax1.twinx()\n",
    "l2, = ax2.plot(vd_result.published, color='green', linewidth=2, label='published')\n",
    "plt.xticks(rotation=90)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Sentiment')\n",
    "ax2.set_ylabel('Published')\n",
    "plt.title('Twitter Sentiment Vader Model vs Published Consumer Confidence', fontsize=14)\n",
    "plt.legend(['model', 'published'], loc='lower center')\n",
    "plt.xlim([datetime.datetime(2015, 12, 31), datetime.datetime(2022, 12, 31)])\n",
    "for year in range(2010, 2023):\n",
    "    plt.axvline(pd.to_datetime(str(year) + '-01-01'), color='k', linestyle='--', alpha=0.2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9631cd90-f30a-4efb-83fd-ec8706cdbaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76252632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab9e13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
